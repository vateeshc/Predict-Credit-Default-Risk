---
title: "R Notebook - kaggle credit default risk"
output: html_notebook
---

```{r}
setwd("/Users/praneesh/Downloads/All")
```


```{r}
# General 
library(tidyverse)
library(skimr)

# Preprocessing
library(recipes)

#track time
devtools::install_github("jabiru/tictoc")
library(tictoc)

```

```{r}
application_train_tbl <- read_csv("application_train.csv")
application_test_tbl  <- read_csv("application_test.csv")
```


```{r}
application_train_tbl %>%
    slice(1:10) %>%
    knitr::kable()
```

```{r}
# Training data: Separate into x and y tibbles
x_train_tbl <- application_train_tbl %>% select(-TARGET)
y_train_tbl <- application_train_tbl %>% select(TARGET)   

# Testing data: What we submit in the competition
x_test_tbl  <- application_test_tbl

# Remove the original data to save memory
rm(application_train_tbl)
rm(application_test_tbl)
```

```{r}
skim_to_list(x_train_tbl)
```

```{r}
string_2_factor_names <- x_train_tbl %>%
    select_if(is.character) %>%
    names()

string_2_factor_names
```

```{r}
unique_numeric_values_tbl <- x_train_tbl %>%
    select_if(is.numeric) %>%
    map_df(~ unique(.) %>% length()) %>%
    gather() %>%
    arrange(value) %>%
    mutate(key = as_factor(key))

unique_numeric_values_tbl
```

```{r}
factor_limit <- 7

num_2_factor_names <- unique_numeric_values_tbl %>%
    filter(value < factor_limit) %>%
    arrange(desc(value)) %>%
    pull(key) %>%
    as.character()

num_2_factor_names
```

```{r}
missing_tbl <- x_train_tbl %>%
    summarize_all(.funs = ~ sum(is.na(.)) / length(.)) %>%
    gather() %>%
    arrange(desc(value)) %>%
    filter(value > 0)

missing_tbl
```

```{r}
#Preprocessing Implementation And H2O Modeling
rec_obj <- recipe(~ ., data = x_train_tbl) %>%
    step_string2factor(string_2_factor_names) %>%
    step_num2factor(num_2_factor_names) %>%
    step_meanimpute(all_numeric()) %>%
    step_modeimpute(all_nominal()) %>%
    prep(stringsAsFactors = FALSE)

rec_obj
```

```{r}
#bake in the transformations into the train and test sets
x_train_processed_tbl <- bake(rec_obj, x_train_tbl) 
x_test_processed_tbl  <- bake(rec_obj, x_test_tbl)
```

```{r}
# Before transformation
x_train_tbl %>%
    select(1:30) %>%
    glimpse()
```

```{r}
# After transformation
x_train_processed_tbl %>%
    select(1:30) %>%
    glimpse()
```

Summary of train data:

```{r}

factors <- c(num_2_factor_names,string_2_factor_names)

for (i in seq(factors)) {
  f <- bind_cols(x_train_processed_tbl, y_train_processed_tbl) %>%
  group_by_(.dots=factors[i]) %>%
  summarize(count=n(),rate=mean(as.integer(TARGET))-1) %>% # don't ask! seems like a bug in R??
  arrange(desc(count))
  print(f)
}

    
```

```{r}
y_train_processed_tbl <- y_train_tbl %>%
    mutate(TARGET = TARGET %>% as.character() %>% as.factor())
```

```{r}
rm(rec_obj)
rm(x_train_tbl)
rm(x_test_tbl)
rm(y_train_tbl)
```

Only run next chunck if needed.

```{r}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }

# Next, we download packages that H2O depends on.
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wright/5/R")
```

```{r}
# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()
```

```{r}
h2o.no_progress()
```

```{r}
data_h2o <- as.h2o(bind_cols(y_train_processed_tbl, x_train_processed_tbl))
```

```{r}
splits_h2o <- h2o.splitFrame(data_h2o, ratios = c(0.7, 0.15), seed = 1234)

train_h2o <- splits_h2o[[1]]
valid_h2o <- splits_h2o[[2]]
test_h2o  <- splits_h2o[[3]]
```

Creating target encoding map on ORG_TYPE

```{r}
#train_h2o$fold <- h2o.kfold_column(train_h2o, 5, seed = 1234)
te_map <- h2o.target_encode_create(train_h2o, x = list("ORGANIZATION_TYPE"),
                                   y = "TARGET"
                                   #, fold_column = "fold"
                                   )
head(te_map$ORGANIZATION_TYPE)
```

Apply the target encoding to the training and test data sets. Use the following param for the training data:
holdout_type" "KFold"
blended_avg: TRUE
noise_level: NULL(by default it will add 0.01 * range of y of random noise)

```{r}
ext_train_h2o <- h2o.target_encode_apply(train_h2o, x = list("ORGANIZATION_TYPE"), y = "TARGET",
                                     target_encode_map = te_map, 
                                     holdout_type = "None",#KFold
                                     #fold_column = "fold",
                                     blended_avg = FALSE, noise_level = 0
                                     #, seed = 1234
                                     )

#head(ext_train_h2o[c("ORGANIZATION_TYPE", "fold", "TargetEncode_ORGANIZATION_TYPE")])
head(ext_train_h2o[c("ORGANIZATION_TYPE", "TargetEncode_ORGANIZATION_TYPE")])
```

For the validation & testing data, use the parameters:
holdout_type: “None”
blended_avg: False
noise_level: 0

```{r}
ext_valid_h2o <- h2o.target_encode_apply(valid_h2o, x = list("ORGANIZATION_TYPE"), y = "TARGET",
                                    target_encode_map = te_map, holdout_type = "None",
                                    #fold_column = "fold",
                                    blended_avg = FALSE, noise_level = 0)

head(ext_valid_h2o[c("ORGANIZATION_TYPE", "TargetEncode_ORGANIZATION_TYPE")])
```

```{r}
ext_test_h2o <- h2o.target_encode_apply(test_h2o, x = list("ORGANIZATION_TYPE"), y = "TARGET",
                                    target_encode_map = te_map, holdout_type = "None",
                                    #fold_column = "fold",
                                    blended_avg = FALSE, noise_level = 0)

head(ext_test_h2o[c("ORGANIZATION_TYPE", "TargetEncode_ORGANIZATION_TYPE")])
```

Train model with KFold target encoding. Replace ORGANIZATION_TYPE with TargetEncode_ORGANIZATION_TYPE.

```{r}
y <- "TARGET"
x <- setdiff(names(ext_train_h2o), c(y,"ORGANIZATION_TYPE"))

tic("Model_Training")

automl_models_h2o <- h2o.automl(
    x = x,
    y = y,
    training_frame    = ext_train_h2o,
    validation_frame  = ext_valid_h2o,
    leaderboard_frame = ext_test_h2o,
    #fold_column = "fold",
    #exclude_algos = c("DRF", "GBM"), #tree based not ideal for large number of columns in train set
    max_models = 5, #stop when either max of 5 models built or time runs out.
    max_runtime_secs  = 900
)

toc()

automl_leader <- automl_models_h2o@leader


```

```{r}
performance_h2o <- h2o.performance(model = automl_leader, newdata = ext_test_h2o)
```

```{r}
performance_h2o %>%
    h2o.confusionMatrix()
```

```{r}
performance_h2o %>%
    h2o.auc()
```

Add target encoding variable to new data and remove old variables.
```{r}
newdata_h2o <- as.h2o(x_test_processed_tbl)
ext_newdata_h2o <- h2o.target_encode_apply(newdata_h2o, x = list("ORGANIZATION_TYPE"), 
                                    y = "TARGET",
                                    target_encode_map = te_map, holdout_type = "None",
                                    #fold_column = "fold",
                                    blended_avg = FALSE, noise_level = 0)

head(ext_newdata_h2o[c("ORGANIZATION_TYPE", "TargetEncode_ORGANIZATION_TYPE")])

```

```{r}
#prediction_h2o <- h2o.predict(automl_leader, newdata = as.h2o(x_test_processed_tbl)) 
ext_newdata_h2o <- ext_newdata_h2o[,2:ncol(ext_newdata_h2o)]
prediction_h2o <- h2o.predict(automl_leader, newdata = as.h2o(ext_newdata_h2o)) 

```

```{r}
prediction_tbl <- prediction_h2o %>%
    as.tibble() %>%
    bind_cols(
        x_test_processed_tbl %>% select(SK_ID_CURR)
    ) %>%
    select(SK_ID_CURR, p1) %>%
    rename(TARGET = p1)

prediction_tbl
```

```{r}
prediction_tbl %>%
    write_csv(path = "submission_005.csv")
```