---
title: "R Notebook - kaggle credit default risk"
output:
  html_document:
    df_print: paged
---

```{r}
setwd("/Users/praneesh/Downloads/All")
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}
# General 
library(tidyverse)
library(skimr)

# Preprocessing
library(recipes)

# Machine Learning
library(h2o)

# Local Interpretable Model-agnostic Explanations (LIME) is a visualization technique that helps explain individual predictions. 
# install vip from github repo: devtools::install_github("koalaverse/vip")
# library(lime)       # ML local interpretation - Visualizing ML Models with LIME
# library(vip)        # ML global interpretation - variable importance
# library(pdp)        # ML global interpretation - partial dependence plots
library(ggplot2)    # visualization pkg leveraged by above packages
```

```{r}
application_train_tbl <- read_csv("application_train.csv")
application_test_tbl  <- read_csv("application_test.csv")
```


```{r}
application_train_tbl %>%
    slice(1:10) %>%
    knitr::kable()
```

```{r}
# Training data: Separate into x and y tibbles
x_train_tbl <- application_train_tbl %>% select(-TARGET)
y_train_tbl <- application_train_tbl %>% select(TARGET)   

# Testing data: What we submit in the competition
x_test_tbl  <- application_test_tbl

# Remove the original data to save memory
rm(application_train_tbl)
rm(application_test_tbl)
```

```{r}
skim_to_list(x_train_tbl)
```

```{r}
string_2_factor_names <- x_train_tbl %>%
    select_if(is.character) %>%
    names()

string_2_factor_names
```

```{r}
unique_numeric_values_tbl <- x_train_tbl %>%
    select_if(is.numeric) %>%
    map_df(~ unique(.) %>% length()) %>%
    gather() %>%
    arrange(value) %>%
    mutate(key = as_factor(key))

unique_numeric_values_tbl
```

```{r}
factor_limit <- 7

num_2_factor_names <- unique_numeric_values_tbl %>%
    filter(value < factor_limit) %>%
    arrange(desc(value)) %>%
    pull(key) %>%
    as.character()

num_2_factor_names
```

```{r}
missing_tbl <- x_train_tbl %>%
    summarize_all(.funs = ~ sum(is.na(.)) / length(.)) %>%
    gather() %>%
    arrange(desc(value)) %>%
    filter(value > 0)

missing_tbl
```

```{r}
#Preprocessing Implementation And H2O Modeling
rec_obj <- recipe(~ ., data = x_train_tbl) %>%
    step_string2factor(string_2_factor_names) %>%
    step_num2factor(num_2_factor_names) %>%
    step_meanimpute(all_numeric()) %>%
    step_modeimpute(all_nominal()) %>%
    prep(stringsAsFactors = FALSE)

rec_obj
```

```{r}
#bake in the transformations into the train and test sets
x_train_processed_tbl <- bake(rec_obj, x_train_tbl) 
x_test_processed_tbl  <- bake(rec_obj, x_test_tbl)
```

```{r}
# Before transformation
x_train_tbl %>%
    select(1:30) %>%
    glimpse()
```

```{r}
# After transformation
x_train_processed_tbl %>%
    select(1:30) %>%
    glimpse()
```

```{r}
y_train_processed_tbl <- y_train_tbl %>%
    mutate(TARGET = TARGET %>% as.character() %>% as.factor())
```

```{r}
rm(rec_obj)
rm(x_train_tbl)
rm(x_test_tbl)
rm(y_train_tbl)
```

```{r}
h2o.init(nthreads = -1)
```

```{r}
h2o.no_progress()
```

```{r}
data_h2o <- as.h2o(bind_cols(y_train_processed_tbl, x_train_processed_tbl))
```

```{r}
splits_h2o <- h2o.splitFrame(data_h2o, ratios = c(0.7, 0.15), seed = 1234)

train_h2o <- splits_h2o[[1]]
valid_h2o <- splits_h2o[[2]]
test_h2o  <- splits_h2o[[3]]
```

```{r}
y <- "TARGET"
x <- setdiff(names(train_h2o), y)
x1 <- setdiff(names(train_h2o), c(y,"ORGANIZATION_TYPE"))

automl_models_h2o <- h2o.automl(
    x = x,
    y = y,
    training_frame    = train_h2o,
    validation_frame  = valid_h2o,
    leaderboard_frame = test_h2o,
    max_runtime_secs  = 90
)
automl_leader <- automl_models_h2o@leader

# drop ORGANIZATION_TYPE due to high cardinality which may be causing overfitting in training!
automl_models_h2o_1 <- h2o.automl(
    x = x1,
    y = y,
    training_frame    = train_h2o,
    validation_frame  = valid_h2o,
    leaderboard_frame = test_h2o,
    max_runtime_secs  = 90
)
automl_leader_1 <- automl_models_h2o_1@leader

```

```{r}
performance_h2o <- h2o.performance(automl_leader, newdata = test_h2o)
performance_h2o_1 <- h2o.performance(automl_leader_1, newdata = test_h2o)
```

```{r}
# built-in PDP support in H2O
h2o.partialPlot(automl_leader, data = train_h2o, cols = names(train_h2o[4]))
```

```{r}
explain_h2o <- h2o.predict(automl_leader, newdata = train_h2o)

explain_tbl <- explain_h2o %>%
    as.tibble() %>%
    bind_cols(
      as.tibble(train_h2o)
      ) 

head(explain_tbl)

```

```{r}
ggplot(explain_tbl, aes(x=log(AMT_INCOME_TOTAL),y=p1)) +
  geom_jitter()
```
```{r}
explain_tbl_factors <-
    explain_tbl %>% 
    keep(is.factor) %>%
      bind_cols(
        explain_tbl %>% select(p1)
              )
 names_factors <- names(explain_tbl_factors)
```

```{r}
for (i in seq(names_factors)) {
  plot <- ggplot(explain_tbl_factors, aes(y=p1)) +
    aes_string(group=names_factors[i]) +
    geom_boxplot()
  print(plot)
}
```

```{r}
performance_h2o %>%
    h2o.confusionMatrix()
```

```{r}
performance_h2o %>%
    h2o.auc()
```

```{r}
prediction_h2o <- h2o.predict(automl_leader, newdata = as.h2o(x_test_processed_tbl)) 

```

```{r}
prediction_tbl <- prediction_h2o %>%
    as.tibble() %>%
    bind_cols(
        x_test_processed_tbl %>% select(SK_ID_CURR)
    ) %>%
    select(SK_ID_CURR, p1) %>%
    rename(TARGET = p1)

prediction_tbl
```

```{r}
prediction_tbl %>%
    write_csv(path = "submission_001.csv")
```