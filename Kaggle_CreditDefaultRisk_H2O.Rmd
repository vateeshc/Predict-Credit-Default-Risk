---
title: "R Notebook - kaggle credit default risk"
output: html_notebook
---

```{r}
setwd("/Users/praneesh/Downloads/All")
```


```{r}
# General 
library(tidyverse)
library(skimr)

# Preprocessing
library(recipes)

#track time
devtools::install_github("jabiru/tictoc")
library(tictoc)

```

```{r}
application_train_tbl <- read_csv("application_train.csv")
application_test_tbl  <- read_csv("application_test.csv")
```

Import linked files
```{r}
previous_application <- read_csv("previous_application.csv")
install_payments <- read_csv("installments_payments.csv")
bureau <- read_csv("bureau.csv")
pos_cash_bal <- read_csv("POS_CASH_balance.csv")
bureau_bal <- read_csv("bureau_balance.csv")
credit_card_bal <- read_csv("credit_card_balance.csv")
data_dict <- read_csv("HomeCredit_columns_description.csv")

```

```{r}
head(x_train_processed_tbl)
head(previous_application)
head(bureau)
head(pos_cash_bal)
head(credit_card_bal)
#head(bureau_bal)

filter(previous_application,SK_ID_CURR==100001)
filter(bureau,SK_ID_CURR==100001)
filter(pos_cash_bal,SK_ID_CURR==100001)
filter(credit_card_bal,SK_ID_CURR==363914)
#filter(bureau_bal,SK_BUREAU_ID==271877)

```

Derive from linked data:
# number of previous applications at Home Credit
# number of previous applications at other institutes
# total amount applied for in previous applications
# number of approvals previous at Home Credit
# Days since last application
# amount of last application
```{r}
#summary(previous_application)
x_previous_application <-
previous_application %>% 
  group_by(SK_ID_CURR) %>%
  summarise(Pre_appl_count = n(), 
            Pre_amt_appl = mean(AMT_APPLICATION),
            Pre_amt_credit = mean(AMT_CREDIT),
            Pre_amt_annuity = mean(AMT_ANNUITY, na.rm=TRUE),
            Pre_amt_goods = mean(AMT_GOODS_PRICE, na.rm=TRUE)

              )

x_previous_approved <- 
  filter(previous_application,NAME_CONTRACT_STATUS=="Approved") %>% 
  group_by(SK_ID_CURR) %>%
  summarise(Pre_appl_approved_count = n(), 
            Pre_amt_approved_appl = mean(AMT_APPLICATION),
            Pre_amt_approved_credit = mean(AMT_CREDIT),
            Pre_amt_approved_annuity = mean(AMT_ANNUITY, na.rm=TRUE),
            Pre_amt_approved_goods = mean(AMT_GOODS_PRICE, na.rm=TRUE)

              )

x_previous_application <-
  left_join(x_previous_application, x_previous_approved, by="SK_ID_CURR")


filter(previous_application,SK_ID_CURR==100006)
filter(x_previous_application,SK_ID_CURR==100006)
filter(x_previous_approved,SK_ID_CURR==100006)

#get bureau data on previous applications at other institutes
x_bureau_application <-
bureau %>% 
  group_by(SK_ID_CURR) %>%
  summarise(Bur_appl_count = n(), 
            Bur_amt_credit = mean(AMT_CREDIT_SUM),
            Bur_amt_credit_debt = mean(AMT_CREDIT_SUM_DEBT, na.rm=TRUE),
            Bur_amt_annuity = mean(AMT_ANNUITY, na.rm=TRUE)
          
              )

x_bureau_active <-
filter(bureau,CREDIT_ACTIVE=="Active") %>% 
  group_by(SK_ID_CURR) %>%
  summarise(Bur_active_appl_count = n(), 
            Bur_active_amt_credit = mean(AMT_CREDIT_SUM),
            Bur_active_amt_credit_debt = mean(AMT_CREDIT_SUM_DEBT, na.rm=TRUE),
            Bur_active_amt_annuity = mean(AMT_ANNUITY, na.rm=TRUE)
          
              )

x_bureau_application <-
  left_join(x_bureau_application, x_bureau_active, by="SK_ID_CURR")

#get credit card and pos_cash data
x_credit_card <-
  credit_card_bal %>%
  group_by(SK_ID_CURR) %>%
  summarise(Credit_card_rows = n(),
            Credit_card_DPD = sum(SK_DPD, na.rm =TRUE)
  )

x_credit_card_bal <-
   left_join( 
  credit_card_bal %>%
  group_by(SK_ID_CURR, SK_ID_PREV) %>%
  summarise(MONTHS_BALANCE = max(MONTHS_BALANCE)),
select(credit_card_bal,c("SK_ID_CURR", "SK_ID_PREV","MONTHS_BALANCE","AMT_BALANCE")),
by=c("SK_ID_CURR", "SK_ID_PREV","MONTHS_BALANCE")
)

x_credit_card <-
  left_join( x_credit_card,
            x_credit_card_bal %>%
              group_by(SK_ID_CURR) %>%
              summarise(credit_card_recent_bal = mean(AMT_BALANCE)),
            by="SK_ID_CURR")

#pos cash summary data

x_pos_cash <-
  pos_cash_bal %>%
  group_by(SK_ID_CURR) %>%
  summarise(Pos_cash_rows = n(),
            Pos_cash_DPD = sum(SK_DPD, na.rm = TRUE)
  )

filter(x_bureau_application,SK_ID_CURR==100001)
filter(x_bureau_active,SK_ID_CURR==100001)
filter(bureau,SK_ID_CURR==100001)
filter(x_credit_card,SK_ID_CURR==380010)
filter(credit_card_bal,SK_ID_CURR==380010) %>% arrange(SK_ID_CURR, SK_ID_PREV, desc(MONTHS_BALANCE))
filter(pos_cash_bal,SK_ID_CURR==100001)
filter(x_pos_cash,SK_ID_CURR==100001)
#merge all previous application with Train & Test data.

#1. merge into Train
application_train_tbl_extra <-
  left_join(application_train_tbl, x_previous_application,by="SK_ID_CURR") %>%
  left_join(x_bureau_application, by="SK_ID_CURR") %>%
  left_join(x_credit_card,by="SK_ID_CURR") %>%
  left_join(x_pos_cash,by="SK_ID_CURR")

#names to replace na with 0

replace_with_0 <- c("AMT_REQ_CREDIT_BUREAU_HOUR" ,  "AMT_REQ_CREDIT_BUREAU_DAY"  ,  "AMT_REQ_CREDIT_BUREAU_WEEK"  , "AMT_REQ_CREDIT_BUREAU_MON"   ,
"AMT_REQ_CREDIT_BUREAU_QRT"  ,  "AMT_REQ_CREDIT_BUREAU_YEAR"  , "Pre_appl_count",               "Pre_amt_appl"      ,          
"Pre_amt_credit"      ,         "Pre_amt_annuity"       ,       "Pre_amt_goods"   ,             "Pre_appl_approved_count" ,    
"Pre_amt_approved_appl" ,       "Pre_amt_approved_credit" ,     "Pre_amt_approved_annuity"   ,  "Pre_amt_approved_goods"  ,    
"Bur_appl_count"       ,        "Bur_amt_credit"          ,     "Bur_amt_credit_debt"    ,      "Bur_amt_annuity"      ,       
"Bur_active_appl_count" ,       "Bur_active_amt_credit"   ,     "Bur_active_amt_credit_debt" ,  "Bur_active_amt_annuity"  ,    
"Credit_card_rows"     ,        "Credit_card_DPD"        ,      "credit_card_recent_bal"   ,    "Pos_cash_rows"       ,        
"Pos_cash_DPD"    )


head(application_train_tbl_extra)

# Replace missing values with 0
for (i in seq_along(replace_with_0)){
application_train_tbl_extra[is.na(application_train_tbl_extra[,replace_with_0[i]]), replace_with_0[i]] <- 0
}

#2. merge into Test
application_test_tbl_extra <- 
  left_join(application_test_tbl, x_previous_application,by="SK_ID_CURR") %>%
  left_join(x_bureau_application, by="SK_ID_CURR") %>%
  left_join(x_credit_card,by="SK_ID_CURR") %>%
  left_join(x_pos_cash,by="SK_ID_CURR")

head(application_test_tbl_extra)

# Replace missing values with 0
for (i in seq_along(replace_with_0)){
application_test_tbl_extra[is.na(application_test_tbl_extra[,replace_with_0[i]]), replace_with_0[i]] <- 0
}

```

```{r}
#View(data_dict)
hist(credit_card_bal$MONTHS_BALANCE)
```

```{r}
```

```{r}
application_train_tbl %>%
    slice(1:10) %>%
    knitr::kable()
```

```{r}
# Training data: Separate into x and y tibbles
x_train_tbl <- application_train_tbl_extra %>% select(-TARGET)
y_train_tbl <- application_train_tbl_extra %>% select(TARGET)   

# Testing data: What we submit in the competition
x_test_tbl  <- application_test_tbl_extra

# Remove the original data to save memory
rm(application_train_tbl)
rm(application_test_tbl)
rm(bureau)
rm(bureau_bal)
rm(credit_card_bal)
rm(install_payments)
rm(pos_cash_bal)
```

```{r}
skim_to_list(x_train_tbl)
```

```{r}
string_2_factor_names <- x_train_tbl %>%
    select_if(is.character) %>%
    names()

string_2_factor_names
```

```{r}
unique_numeric_values_tbl <- x_train_tbl %>%
    select_if(is.numeric) %>%
    map_df(~ unique(.) %>% length()) %>%
    gather() %>%
    arrange(value) %>%
    mutate(key = as_factor(key))

unique_numeric_values_tbl
```

```{r}
factor_limit <- 7

num_2_factor_names <- unique_numeric_values_tbl %>%
    filter(value < factor_limit) %>%
    arrange(desc(value)) %>%
    pull(key) %>%
    as.character()

num_2_factor_names
```

```{r}
missing_tbl <- x_train_tbl %>%
    summarize_all(.funs = ~ sum(is.na(.)) / length(.)) %>%
    gather() %>%
    arrange(desc(value)) %>%
    filter(value > 0)

missing_tbl
```

```{r}
#Preprocessing Implementation And H2O Modeling
rec_obj <- recipe(~ ., data = x_train_tbl) %>%
    step_string2factor(string_2_factor_names) %>%
    step_num2factor(num_2_factor_names) %>%
    step_meanimpute(all_numeric()) %>%
    step_modeimpute(all_nominal()) %>%
    prep(stringsAsFactors = FALSE)

rec_obj
```

```{r}
#bake in the transformations into the train and test sets
x_train_processed_tbl <- bake(rec_obj, x_train_tbl) 
x_test_processed_tbl  <- bake(rec_obj, x_test_tbl)
```

```{r}
# Before transformation
x_train_tbl %>%
    select(1:30) %>%
    glimpse()
```

```{r}
# After transformation
x_train_processed_tbl %>%
    select(1:30) %>%
    glimpse()
```



```{r}
y_train_processed_tbl <- y_train_tbl %>%
    mutate(TARGET = TARGET %>% as.character() %>% as.factor())
```

```{r}
rm(rec_obj)
rm(x_train_tbl)
rm(x_test_tbl)
rm(y_train_tbl)
```

Only run next chunck if needed.

```{r}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }

# Next, we download packages that H2O depends on.
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wright/5/R")
```

```{r}
# Finally, let's load H2O and start up an H2O cluster
library(h2o)
#h2o.shutdown()
h2o.init(nthreads=-1, max_mem_size = '2g')
```

```{r}
h2o.no_progress()
```

```{r}
data_h2o <- as.h2o(bind_cols(y_train_processed_tbl, x_train_processed_tbl))
```

```{r}
splits_h2o <- h2o.splitFrame(data_h2o, ratios = c(0.9), seed = 1234)

train_h2o <- splits_h2o[[1]]
te_holdout_h2o <- splits_h2o[[2]]

```

Creating target encoding map on all categoricals

```{r}
#te_cols <- x_train_processed_tbl %>%
#			select_if(is.factor) %>%
 #     names()


te_cols<- c(     
       "OCCUPATION_TYPE"      ,      
    "ORGANIZATION_TYPE"    
)

te_map <- h2o.target_encode_create(te_holdout_h2o, x = as.list(te_cols), y = "TARGET")
te_map$ORGANIZATION_TYPE
te_map$OCCUPATION_TYPE

```

Apply the target encoding to the training and test data sets. Use the following param for the training data:
holdout_type" "KFold"
blended_avg: TRUE
noise_level: NULL(by default it will add 0.01 * range of y of random noise)

```{r}

ext_train_h2o <- h2o.target_encode_apply(train_h2o, x = as.list(te_cols), y = "TARGET",
                                     target_encode_map = te_map, 
                                     holdout_type = "None",
                                      noise_level = 0,
                                     seed = 1234
                                     )

head(ext_train_h2o[c("ORGANIZATION_TYPE", "TargetEncode_ORGANIZATION_TYPE")])
head(ext_train_h2o[c("OCCUPATION_TYPE", "TargetEncode_OCCUPATION_TYPE")])

```


```{r}

```

```{r}

```

Train model with holdout target encoding. Replace Categorical with TargetEncoded variables.

```{r}
y <- "TARGET"
x <- setdiff(names(train_h2o), c(y))

tic("Model_Training")

automl_models_h2o <- h2o.automl(
    x = x,
    y = y,
    training_frame    = train_h2o,
    nfolds = 5,
    #max_models = 10, #stop when either max of # models built or time runs out.
    max_runtime_secs  = 180
        # Early Stopping
    #stopping_rounds = 5, stopping_metric = "AUC", 
    #stopping_tolerance = 0.001, seed = 1234

)

toc()

automl_leader <- automl_models_h2o@leader


```

```{r}
performance_h2o <- h2o.performance(model = automl_leader, newdata = test_h2o)
```

```{r}
performance_h2o %>%
    h2o.confusionMatrix()
```

```{r}
performance_h2o %>%
    h2o.auc()
```

Add target encoding variable to new data and remove old variables.
```{r}
newdata_h2o <- as.h2o(x_test_processed_tbl)
ext_newdata_h2o <- h2o.target_encode_apply(newdata_h2o, x = as.list(te_cols), 
                                    y = "TARGET",
                                    target_encode_map = te_map, 
                                    holdout_type = "None",
                                    noise_level = 0)

head(ext_newdata_h2o[c("ORGANIZATION_TYPE", "TargetEncode_ORGANIZATION_TYPE")])

```

```{r}
prediction_h2o <- h2o.predict(automl_leader, newdata = as.h2o(x_test_processed_tbl)) 


```

```{r}
prediction_tbl <- prediction_h2o %>%
    as.tibble() %>%
    bind_cols(
        x_test_processed_tbl %>% select(SK_ID_CURR)
    ) %>%
    select(SK_ID_CURR, p1) %>%
    rename(TARGET = p1)

prediction_tbl
```

```{r}
prediction_tbl %>%
    write_csv(path = "submission_007.csv")
```